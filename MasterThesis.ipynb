{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MasterThesis.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "7LehLdP2o-nD"
      },
      "cell_type": "markdown",
      "source": [
        "Drive Mounth"
      ]
    },
    {
      "metadata": {
        "id": "9d9_XZYtBCnd"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5m_vjHNVpCC_"
      },
      "cell_type": "code",
      "source": [
        "#colab\n",
        "# google-drive-ocamlfuseのインストール\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "# Colab用のAuth token作成\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Drive FUSE library用のcredential生成\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "# drive/ を作り、そこにGoogle Driveをマウントする\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "14NSIWS1BD9g"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0gjk0E1_pUZm"
      },
      "cell_type": "markdown",
      "source": [
        "Install and import Libraries"
      ]
    },
    {
      "metadata": {
        "id": "i3xE-Nm-pYZG"
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/librosa/librosa\n",
        "!pip install np_utils\n",
        "!pip install keras\n",
        "!pip install pyeasyga\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "import glob\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import np_utils\n",
        "import pyeasyga\n",
        "\n",
        "from pyeasyga import pyeasyga\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from sklearn.cluster import MeanShift\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used dataset https://www.kaggle.com/c/freesound-audio-tagging/data"
      ],
      "metadata": {
        "id": "GVLyqR_diizO"
      }
    },
    {
      "metadata": {
        "id": "pN9eLpAbrXVf"
      },
      "cell_type": "markdown",
      "source": [
        "**Load Data**"
      ]
    },
    {
      "metadata": {
        "id": "02c1s7zirYYq"
      },
      "cell_type": "code",
      "source": [
        "def load_sound_files(file_paths):\n",
        "    raw_sounds = []\n",
        "    for fp in file_paths:\n",
        "        fp=\"drive/app/TUDiplomna/audio/\"+fp\n",
        "        X,sr = librosa.load(fp)\n",
        "        raw_sounds.append(X)\n",
        "    return raw_sounds\n",
        "\n",
        "start = time.time()\n",
        "mypath=\"drive/app/TUDiplomna/audio/\"\n",
        "labelsN=[\"Acoustic_guitar\", \"Applause\", \"Bark\", \"Bass_drum\", \"Burping_or_eructation\", \"Bus\", \"Cello\", \"Chime\", \"Clarinet\", \"Computer_keyboard\"]\n",
        "onlyfiles = []\n",
        "tr_labels=pd.read_csv(\"drive/app/TUDiplomna/train.csv\" , error_bad_lines=False)\n",
        "for f in range(len(tr_labels)):\n",
        "  if tr_labels.iloc[f].label in labelsN:\n",
        "    onlyfiles.append(tr_labels.iloc[f].fname)\n",
        "end = time.time()\n",
        "print(\"Time for data loading:\")\n",
        "print(end - start)\n",
        "print(\"seconds\")\n",
        "random.shuffle(onlyfiles,random.random) #mix files\n",
        "train_files= onlyfiles[:500] \n",
        "test_files= onlyfiles[500:600]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uW3GujJ5r2Pp"
      },
      "cell_type": "markdown",
      "source": [
        "#Feature Extraction"
      ]
    },
    {
      "metadata": {
        "id": "HsTwycG2r8zf"
      },
      "cell_type": "code",
      "source": [
        "def extract_feature(file_name):\n",
        "    X, sample_rate = librosa.load(file_name)\n",
        "    stft = np.abs(librosa.stft(X))\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "    return mfccs,chroma,mel,contrast\n",
        "\n",
        "def parse_audio_files(files_names):\n",
        "    features, labels = np.empty((0,187)), np.empty(0)\n",
        "    counter=0\n",
        "    for fn in files_names:\n",
        "      try:\n",
        "        mfccs, chroma, mel, contrast = extract_feature(\"drive/app/TUDiplomna/audio/\"+fn)\n",
        "      except Exception as e:\n",
        "        counter=counter+1\n",
        "        continue\n",
        "      ext_features = np.hstack([mfccs,chroma,mel,contrast])\n",
        "      features = np.vstack([features,ext_features])\n",
        "      labels = np.append(labels, fn)\n",
        "    #print(counter)\n",
        "    return features,labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p36ZR_HdsA6_"
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "tr_features, tr_files= parse_audio_files(train_files)\n",
        "ts_features, ts_files = parse_audio_files(test_files)\n",
        "end = time.time()\n",
        "print(\"Time for extracting test and train features:\")\n",
        "print(end - start)\n",
        "print(\"seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nfHbhlCQsiUC"
      },
      "cell_type": "code",
      "source": [
        "def lablesExtraction(files,labels):\n",
        "  labelsSet=[]\n",
        "  for i in range(0, len(files)):\n",
        "    for j in range(0, 9472):#check where this num come from\n",
        "      if files[i]==labels['fname'].values[j]:\n",
        "        label=labels['label'].values[j]\n",
        "        if label != \"Acoustic_guitar\" and label != \"Applause\" and label != \"Bark\" and label != \"Bass_drum\" and label != \"Bus\":\n",
        "          labelsSet.append('None')\n",
        "        else:m\n",
        "          labelsSet.append(label)\n",
        "        break\n",
        "  return labelsSet\n",
        "\n",
        "def oneHotEncodder(labels):\n",
        "  encoder = LabelEncoder()\n",
        "  encoder.fit(labels)\n",
        "  encoded_Y = encoder.transform(labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sQHiJ8u9sw-j"
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "tr_features, tr_files= parse_audio_files(train_files)\n",
        "ts_features, ts_files = parse_audio_files(test_files)\n",
        "\n",
        "X_train=pd.DataFrame(tr_features)\n",
        "labels_train=lablesExtraction(tr_files,tr_labels)\n",
        "Y_train=oneHotEncodder(labels_train)\n",
        "#pd.DataFrame(tr_labels)\n",
        "\n",
        "X_test=pd.DataFrame(ts_features)\n",
        "labels_test=lablesExtraction(ts_files,tr_labels)\n",
        "Y_test=oneHotEncodder(labels_test)\n",
        "\n",
        "end = time.time()\n",
        "print(\"Time for extracting test and train features and labels:\")\n",
        "print(end - start)\n",
        "print(\"seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_XG_9qB4tB8b"
      },
      "cell_type": "markdown",
      "source": [
        "#**Classification**\n"
      ]
    },
    {
      "metadata": {
        "id": "z57I4PrKtCuE"
      },
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "\t# create model -Baseline: 53.72% (15.21%)\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(187, input_dim=187, activation='relu'))\n",
        "\tmodel.add(Dense(6, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gBgnX-WPtJJS"
      },
      "cell_type": "code",
      "source": [
        "def nn_dropout():#Baseline: 75.87% (9.01%)\n",
        "  model = Sequential()\n",
        "  model.add(Dense(18, input_dim=187, init='uniform', activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(18, init='uniform', activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(6, init='uniform', activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wDYBJLtMtMuM"
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, Y_train, epochs=150, batch_size=10, verbose=0)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "end = time.time()\n",
        "print(\"Time for executing  one layered perceptron\")\n",
        "print(end - start)\n",
        "print(\"seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2K9gOBZntNQ1"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "start = time.time()\n",
        "model = Sequential()\n",
        "model.add(Dense(18, input_dim=187, activation='relu'))\n",
        "model.add(Dense(18, activation='relu'))\n",
        "model.add(Dense(6, activation='sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "history=model.fit(X_train, Y_train, epochs=150, batch_size=10, verbose=0)#history\n",
        "end= time.time()\n",
        "\n",
        "print(\"compile time in sec:\")\n",
        "print(end-start)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "end = time.time()\n",
        "print(\"Time for executing  two layers perceptron\")\n",
        "print(end - start)\n",
        "print(\"seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GemIUlIDtSEx"
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "model = nn_dropout()\n",
        "# Fit the model\n",
        "model.fit(X_train, Y_train, epochs=150, batch_size=10, verbose=0)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "end = time.time()\n",
        "print(\"Time for executing  two layers perceptron with drop out\")\n",
        "print(end - start)\n",
        "print(\" in seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OfDslNQCR0-8"
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "# all parameters not specified are set to their defaults\n",
        "logisticRegr = LogisticRegression()\n",
        "logisticRegr.fit(X_train, labels_train)\n",
        "# Use score method to get accuracy of model\n",
        "score = logisticRegr.score(X_test,labels_test)\n",
        "print(\"Accuracy:\")\n",
        "print(score)\n",
        "end = time.time()\n",
        "print(\"Time for executing linear regression model\")\n",
        "print(end - start)\n",
        "print(\" in seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ssYdgi2tznK"
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "# all parameters not specified are set to their defaults\n",
        "logisticRegr = LogisticRegression(multi_class=multinomial,solver=newton-cg)\n",
        "logisticRegr.fit(X_train, labels_train)\n",
        "# Use score method to get accuracy of model\n",
        "score = logisticRegr.score(X_test,labels_test)\n",
        "print(\"Accuracy:\")\n",
        "print(score)\n",
        "end = time.time()\n",
        "print(\"Time for executing linear regression model\")\n",
        "print(end - start)\n",
        "print(\" in seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E7NSuemX9nAM"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "z50RSSic9nYh"
      },
      "cell_type": "code",
      "source": [
        "st= time.time()\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_trai, Y_train)\n",
        "core=classifier.score(X_test, Y_test)\n",
        "print(\"Mean accuracy on the given test data and labels.\")\n",
        "print(score)\n",
        "print('Metrics for Multinominal Naive bayes classificator ')\n",
        "print ('Total score: '+str(np.mean(scores)))\n",
        "print ('Total time: '+str(int(time.time()-st)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yr6MXLTiEG6P"
      },
      "cell_type": "code",
      "source": [
        "st= time.time()\n",
        "classifier = RandomForestClassifier(n_estimators=50, max_depth=50, random_state=1)\n",
        "classifier.fit(X_trai, Y_train)\n",
        "core=classifier.score(X_test, Y_test)\n",
        "print(\"Mean accuracy on the given test data and labels.\")\n",
        "print(score)\n",
        "print('Metrics for Random Forest classificator')\n",
        "print ('Total score: '+str(np.mean(scores)))\n",
        "print ('Total time: '+str(int(time.time()-st)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hIhM5xieJ73B"
      },
      "cell_type": "code",
      "source": [
        "#RNN\n",
        "embed_dim = 128\n",
        "lstm_out = 200\n",
        "batch_size = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=187, init='uniform', activation='relu', dropout = 0.2))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dense(6,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OVEi7_S6t_xh"
      },
      "cell_type": "markdown",
      "source": [
        "#Clusterization"
      ]
    },
    {
      "metadata": {
        "id": "ledUuMmjUwFZ"
      },
      "cell_type": "code",
      "source": [
        "print(X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QJs7niVKt91Y"
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "#https://scikit-learn.org/stable/modules/clustering.html#mean-shift\n",
        "clustering = MeanShift()\n",
        "cluster_labels = clustering.fit_predict(X)\n",
        "silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "print(\"The average silhouette_score is :\", silhouette_avg)\n",
        "end = time.time()\n",
        "print(\"Time for executing mean shift model\")\n",
        "print(end - start)\n",
        "print(\" in seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oKYtGq8ouLmx"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def fitness(individual, data):\n",
        "    temp=0.77;\n",
        "    cNum=1\n",
        "    for x in data:\n",
        "      if temp / float(2.45) > x['score']:\n",
        "        temp=x['score']\n",
        "        cNum=x['clusterNum']\n",
        "    return cNum\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7zrdy2cevRFw"
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "#KMeans(random init)\n",
        "data=[];\n",
        "for i in range(2,20):\n",
        "  cluster_labels = KMeans(n_clusters=i, init='random', random_state=10).fit_predict(X)\n",
        "  data.append({'clusterNum': i , 'score': silhouette_score(X, cluster_labels)})\n",
        "  \n",
        "# initialise the GA with data\n",
        "ga = pyeasyga.GeneticAlgorithm(data)\n",
        "ga.fitness_function = fitness               # set the GA's fitness function\n",
        "ga.run()                                    # run the GA\n",
        "print ga.best_individual()\n",
        "end = time.time()\n",
        "print(\"Time for executing Kmeans with GA\")\n",
        "print(end - start)\n",
        "print(\" in seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IXruNdW8vR3M"
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "#KMeans++\n",
        "data=[];\n",
        "for i in range(2,20):\n",
        "  cluster_labels = KMeans(n_clusters=i, init='random').fit_predict(X)\n",
        "  data.append({'clusterNum': i , 'score': silhouette_score(X, cluster_labels)})\n",
        "  \n",
        "# initialise the GA with data\n",
        "ga = pyeasyga.GeneticAlgorithm(data)\n",
        "ga.fitness_function = fitness               # set the GA's fitness function\n",
        "ga.run()                                    # run the GA\n",
        "print ga.best_individual()\n",
        "end = time.time()\n",
        "print(\"Time for executing Kmeans++ with GA\")\n",
        "print(end - start)\n",
        "print(\" in seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}